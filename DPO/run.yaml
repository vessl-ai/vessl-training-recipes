name: dpo-finetuning
tags:
  - finetune
  - dpo
import:
  /code/:
    git:
      url: github.com/vessl-ai/vessl-training-recipes.git
      ref: main
export:
  /artifacts/: volume://vessl-storage
resources:
  cluster: vessl-kr-a100-80g-sxm
  preset: gpu-a100-80g-small
image: quay.io/vessl-ai/torch:2.8.0-cuda12.8-r1
run:
  - command: |-
      pip install trl unsloth packaging==24.1
      python train.py \
        --base-model-name $MODEL_NAME \
        --dataset $DATASET_NAME \
        --fraction 0.5 \
        --checkpoint-path /artifacts/checkpoints \
        --output-model-name /artifacts/adapter \
        --train-epochs 1 \
        --lora-rank 8
    workdir: /code/DPO
env:
  MODEL_NAME: unsloth/Qwen3-8B-unsloth-bnb-4bit
  DATASET_NAME: HuggingFaceH4/ultrafeedback_binarized
